{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epop Legacy Parser: Jupyter Notebook\n",
    "\n",
    "The following website is used to generate queries: [ePop Data Explorer](https://edex.phys.ucalgary.ca/). Legacy ephemeris format is used instead of SP3 ephemeris format as readily available parser's are not available. The existing `RINEX` implementations are for GPS satellites. Implementing general purpose SP3 parser would take too long.\n",
    "\n",
    "The following 3rd-Party dependencies are used:\n",
    "- Numpy\n",
    "\n",
    "**How to run notebook**:\n",
    "\n",
    "Option 1: After cloning the repo, execute `uv sync` under this directory\n",
    "    - Assumes you have `uv` installed on your system\n",
    "\n",
    "Option 2: Create a virtual environment, separately install the dependencies, copy the jupyter notebook to the root of the virtual environment\n",
    "\n",
    ">Note: Make sure you download a test ephemeris file and name it accordingly. (Alternatively you can use the following command at the root of `epop_parser`)\n",
    "\n",
    "```bash\n",
    "curl -LO https://epop-data.phys.ucalgary.ca/2013/10/03/CAS_ephemeris_20131003T000000_20131003T235959_1.2.0.txt\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug print\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime, date\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "\n",
    "@dataclass\n",
    "class SwarmEphemerisLegacy:\n",
    "    \"\"\"Dataclass for performing operations with Legacy SWARM-E ephemeris\n",
    "    including File I/O\"\"\"\n",
    "\n",
    "    \"\"\"Ephemeris Collection Data\"\"\"\n",
    "    ephemeris_date: date\n",
    "\n",
    "    \"\"\"Datapoint Time Collection - UTC\"\"\"\n",
    "    data_datetime: list[datetime]\n",
    "\n",
    "    \"\"\"X Position J2000 [km]\"\"\"\n",
    "    X_ITRF: list[np.float32]\n",
    "\n",
    "    \"\"\"X Position J2000 [km]\"\"\"\n",
    "    Y_ITRF: list[np.float32]\n",
    "\n",
    "    \"\"\"X Position J2000 [km]\"\"\"\n",
    "    Z_ITRF: list[np.float32]\n",
    "\n",
    "    \"\"\"Column Names\"\"\"\n",
    "    columns: list[str]\n",
    "\n",
    "    def __init__(self, ephemeris_fname: Path) -> None:\n",
    "        \n",
    "        # Initialize Parameters\n",
    "        self.ephemeris_date = datetime.now()\n",
    "        self.data_datetime = []\n",
    "        self.X_ITRF = []\n",
    "        self.Y_ITRF = []\n",
    "        self.Z_ITRF = []\n",
    "        self.columns = []\n",
    "        self._read_ephemeris_file(fname=ephemeris_fname)\n",
    "\n",
    "    def _read_ephemeris_file(self, fname: Path) -> None:\n",
    "\n",
    "        # There are 2 lines of metdata for each legacy ephemeris file\n",
    "        column_names: list[str] = []\n",
    "        lines: list[str] = []\n",
    "        with open(fname, 'r') as e_file:\n",
    "            lines = e_file.readlines()\n",
    "            strip_newline = lines[1].strip('\\n')\n",
    "            column_names = strip_newline.split(' ')\n",
    "\n",
    "            # Weird naming convention from ePOP as they added space to quternion label\n",
    "            # Consolidating incorrectly split accuracy (Requires Hardcoding)\n",
    "            accuracy = \"\".join([column_names[20], column_names[21], column_names[22]])\n",
    "            column_names[20] = accuracy\n",
    "\n",
    "            # Need to delete the same index twice as the index after the first delete reduces\n",
    "            # list. [NOT RECOMMENDED] but is ok assuming column schema does not change\n",
    "            del column_names[21], column_names[21]\n",
    "\n",
    "        # Parse each data line into their respective data field\n",
    "        for i, line in enumerate(lines):\n",
    "            if (i == 0 or i == 1):\n",
    "                continue\n",
    "\n",
    "            line = line.strip('\\n')\n",
    "            data = line.split(' ')\n",
    "            data = list(filter(None, data))\n",
    "\n",
    "            # Append to datetime list\n",
    "            dt = data[0] + data[1]\n",
    "            dt_obj = datetime.strptime(dt, '%Y%m%d%H%M%S')\n",
    "            self.data_datetime.append(dt_obj)\n",
    "\n",
    "            # Append Position - J2000\n",
    "            self.X_ITRF.append(np.float32(data[2]))\n",
    "            self.Y_ITRF.append(np.float32(data[3]))\n",
    "            self.Z_ITRF.append(np.float32(data[4]))\n",
    "\n",
    "\n",
    "        # Intentionally assign dataclass fields outside of I/O Context\n",
    "        self.ephemeris_date = self.data_datetime[0].date()\n",
    "        self.columns = column_names\n",
    "\n",
    "    def generate_ephemeris_dataframe(self) -> pd.DataFrame:\n",
    "        ...\n",
    "\n",
    "# Testing Dataclass\n",
    "test = Path(\"TEST_EPHM.txt\")\n",
    "EPHEM_OBJ = SwarmEphemerisLegacy(test)\n",
    "print(\"debug print\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scratch Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-10-03 00:00:01\n",
      "debug print\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "test = Path(\"TEST_EPHM.txt\")\n",
    "\n",
    "line_count = 0\n",
    "column_names: list[str] = []\n",
    "lines: list[str] = []\n",
    "lst: list[datetime] = []\n",
    "\n",
    "with open(test, 'r') as f:\n",
    "    # Read Lines\n",
    "    lines = f.readlines()\n",
    "    cn = lines[1].strip('\\n')\n",
    "    column_names = cn.split(' ')\n",
    "\n",
    "    # Need to their naming\n",
    "    accuracy = \"\".join([column_names[20], column_names[21], column_names[22]])\n",
    "    column_names[20] = accuracy\n",
    "\n",
    "    # Need to delete the same index because of serial execution\n",
    "    del column_names[21], column_names[21]\n",
    "\n",
    "for i, line in enumerate(lines):\n",
    "    if (i == 0 or i == 1):\n",
    "        continue\n",
    "    \n",
    "    line = line.strip('\\n')\n",
    "    data = line.split(' ')\n",
    "    data = list(filter(None, data))\n",
    "    \n",
    "    dt = data[0] + data[1]\n",
    "    dt_obj = datetime.strptime(dt, '%Y%m%d%H%M%S')\n",
    "    lst.append(dt_obj)\n",
    "\n",
    "\n",
    "print(lst[1])\n",
    "print(\"debug print\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "UTC\n",
      "<class 'datetime.date'>\n",
      "-3141.5977\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pytz\n",
    "date = '20131003'\n",
    "time = '000013'\n",
    "\n",
    "dt = date + time\n",
    "dt_obj = datetime.strptime(dt, '%Y%m%d%H%M%S')\n",
    "dt_obj_UTC = dt_obj.replace(tzinfo=pytz.UTC)\n",
    "\n",
    "print(dt_obj.tzinfo)\n",
    "print(dt_obj_UTC.tzinfo)\n",
    "\n",
    "print(type(dt_obj.date()))\n",
    "print(np.float32('-3141.5977'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
